# -*- coding: utf-8 -*-
"""
Created on Fri Feb 26 08:22:59 2021

@author: Akash
"""

import pandas as pd
import numpy as np
import pickle

def is_int(x):
    try:int(x)
    except:return False
    else:return True

def is_float(x):
    try:float(x)
    except:return False
    else:return True

def determine_dtypes(file_path):
    # Open train.csv in read mode
    f = open(file_path)
    # Get the headers of all the columns. First row in a csv file are headers.
    headers = f.readline().strip().split(',')
    # Create a dictionary to store dtypes for each column. Keys are the headers of columns.
    dtypes = dict.fromkeys(headers,None)
    # Loop through the data to determine dtypes
    no_of_rows_to_iterate = 100000
    # Iterate over rows
    for i in range(no_of_rows_to_iterate):
        if (i%10000)==0: 
            print(i) # just to see where we are in the loop  
        # Get a list of values in row i
        values = f.readline().strip().split(',')
        # If row does not have enough columns, skip it as it does not help in determining data type
        if len(values)!=83:continue
        # iterate over header and its corresponding value in a row
        for h,v in zip(headers,values):
            # if value is missing
            if v == '':
                if dtypes[h] == 'int32': # replace int with float as nan is a float object
                    dtypes[h] = 'float32'
                continue # continue to the next h,v pair
            # if v is integer
            if is_int(v):
                if dtypes[h] != 'category' and dtypes[h] != 'float32':
                    dtypes[h] = 'int32'
                else:
                    pass
            # if v is floating-point
            elif is_float(v):
                if dtypes[h] != 'category':
                    dtypes[h] = 'float32'
                else:
                    pass
            # if v is neither integer nor floating-point
            else:
                dtypes[h] = 'category'
    f.close()
    return dtypes

def get_dataframe(file_path,dtypes):
    df = pd.read_csv(file_path,dtype=dtypes)
    return df

def determine_optimum_dtypes(df):
    columns = df.columns    
    dtypes_new = {}    
    for col in columns:
        dtype = df[col].dtype
        if dtype == 'float32' or dtype == 'int32':
            minimum = df[col].min()
            maximum = df[col].max()
            if dtype == 'int32':
                if np.iinfo('int8').min <= minimum <= maximum <= np.iinfo('int8').max:
                    dtypes_new[col] = 'int8'
                elif np.iinfo('int16').min <= minimum <= maximum <= np.iinfo('int16').max:
                    dtypes_new[col] = 'int16'
            elif dtype == 'float32':
                if np.finfo('float16').min <= minimum <= maximum <= np.finfo('float16').max:
                    dtypes_new[col] = 'float16'
    dtypes_manual_changes = dict.fromkeys(
        [
            'IsBeta','RtpStateBitfield','IsSxsPassiveMode','AVProductStatesIdentifier','AVProductsInstalled',
            'AVProductsEnabled','HasTpm','CountryIdentifier','CityIdentifier','OrganizationIdentifier',
            'GeoNameIdentifier','LocaleEnglishNameIdentifier','OsBuild','OsSuite','IsProtected','AutoSampleOptIn','SMode','IeVerIdentifier',
            'Firewall','UacLuaenable','Census_OEMNameIdentifier','Census_OEMModelIdentifier',
            'Census_ProcessorCoreCount','Census_ProcessorManufacturerIdentifier',
            'Census_ProcessorModelIdentifier','Census_PrimaryDiskTotalCapacity',
            'Census_SystemVolumeTotalCapacity','Census_HasOpticalDiskDrive','Census_TotalPhysicalRAM',
            'Census_InternalBatteryNumberOfCharges','Census_OSBuildNumber','Census_OSBuildRevision',
            'Census_OSInstallLanguageIdentifier','Census_OSUILocaleIdentifier','Census_IsPortableOperatingSystem',
            'Census_IsFlightsDisabled','Census_FirmwareManufacturerIdentifier','Census_FirmwareVersionIdentifier',
            'Census_IsSecureBootEnabled','Census_IsVirtualDevice','Census_IsTouchEnabled','Census_IsPenCapable',
            'Census_IsAlwaysOnAlwaysConnectedCapable','Wdft_IsGamer','Wdft_RegionIdentifier','HasDetections'
        ],'category')
    dtypes_new.update(dtypes_manual_changes)
    return dtypes_new

def typecast_dataframe(df,dtypes_new):       
    df = df.astype(dtypes_new)
    return df

def get_final_dtypes(df):
    final_dtypes_dict = {col:str(df[col].dtype) for col in df.columns}
    return final_dtypes_dict

def get_absolute_missing_counts(df):
    absolute_missing_counts_dict = {col:df[col].isna().sum() for col in df.columns}
    return absolute_missing_counts_dict

def get_percentage_missing_counts(df,absolute_missing_counts_dict):
    row_count = df.shape[0]
    percentage_missing_counts_dict = {k:100*v/row_count for k,v in absolute_missing_counts_dict.items()}
    return percentage_missing_counts_dict

def drop_columns_with_missing_values(df,percentage_missing_counts_df,threshold_percentage):
    col_names_to_be_discarded = []
    for index,row in percentage_missing_counts_df.iterrows():
        if row[1]> threshold_percentage:
            col_names_to_be_discarded.append(row[0])     
    df = df.drop(col_names_to_be_discarded,axis=1)
    return df

def compute_unique_value_counts(df):
    unique_value_counts_dict = {}
    for col in df.columns:
        if col == 'MachineIdentifier':continue
        unique_value_counts_dict[col] = df[col].value_counts()
    return unique_value_counts_dict
        
if __name__ == '__main__':
    file_path = r'F:\EDUCATION\MS\3_Spring_2021\Spring_2021\Capstone_1\Microsoft_Malware_Prediction\Data\train\train.csv'
    dtypes = determine_dtypes(file_path)
    train_df = get_dataframe(file_path,dtypes)
    train_df.to_pickle(r'F:\EDUCATION\MS\3_Spring_2021\Spring_2021\Capstone_1\Microsoft_Malware_Prediction\Data\train\train_df.pkl')
    dtypes_new = determine_optimum_dtypes(train_df)
    train_df = typecast_dataframe(train_df,dtypes_new)
    train_df.to_pickle(r'F:\EDUCATION\MS\3_Spring_2021\Spring_2021\Capstone_1\Microsoft_Malware_Prediction\Data\train\train_df.pkl')
    final_dtypes_dict = get_final_dtypes(train_df)
    f = open(r'F:\EDUCATION\MS\3_Spring_2021\Spring_2021\Capstone_1\Microsoft_Malware_Prediction\Data\train\final_dtypes_dict.pkl','wb')
    pickle.dump(final_dtypes_dict,f)
    f.close()
    absolute_missing_counts_dict = get_absolute_missing_counts(train_df)
    col_names,absolute_missing_counts = [],[]
    for k,v in absolute_missing_counts_dict.items():
        col_names.append(k)
        absolute_missing_counts.append(v)
    absolute_missing_counts_df = pd.DataFrame.from_dict({'Name':col_names,'MissingCounts':absolute_missing_counts})
    absolute_missing_counts_df.to_csv(r'F:\EDUCATION\MS\3_Spring_2021\Spring_2021\Capstone_1\Microsoft_Malware_Prediction\Data\train\absolute_missing_counts.csv')
    percentage_missing_counts_dict = get_percentage_missing_counts(train_df,absolute_missing_counts_dict)
    col_names,percentage_missing_counts = [],[]
    for k,v in percentage_missing_counts_dict.items():
        col_names.append(k)
        percentage_missing_counts.append(v)
    percentage_missing_counts_df = pd.DataFrame.from_dict({'Name':col_names,'MissingPercentage':percentage_missing_counts})
    percentage_missing_counts_df.to_csv(r'F:\EDUCATION\MS\3_Spring_2021\Spring_2021\Capstone_1\Microsoft_Malware_Prediction\Data\train\percentage_missing_counts.csv')
    train_df = drop_columns_with_missing_values(train_df,percentage_missing_counts_df,50)
    train_df.to_pickle(r'F:\EDUCATION\MS\3_Spring_2021\Spring_2021\Capstone_1\Microsoft_Malware_Prediction\Data\train\train_df.pkl')
    unique_value_counts_dict = compute_unique_value_counts(train_df)
    for col in unique_value_counts_dict:
        unique_value_counts_dict[col].to_csv(r'F:\EDUCATION\MS\3_Spring_2021\Spring_2021\Capstone_1\Microsoft_Malware_Prediction\Data\train\unique_value_counts'+'\\'+col+'.csv')


